{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9044a729",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "- Stemming is a text processing technique used in Natural Language Processing (NLP) that reduces words to their root/base form by removing prefixes or suffixes.\n",
    "- e.g.1: if corpus = [eat, eaten, eating], word root = [eat]\n",
    "- e.g.2: if corpus = [go,going,gone,goes], word root = [go]\n",
    "- Python classes used for Stemming\n",
    "    - 1) PorterStemmer\n",
    "    - 2) RegexpStemmer class\n",
    "        - This class takes a single regular expression and removes prefix or suffixes that match the expression.\n",
    "    - 3) Snowball Stemmer\n",
    "        - Performs better than PorterStemmer\n",
    "        - Multi-language support (e.g. English, Arabic, German, French, etc)\n",
    "- *** Purpose of Stemming ***\n",
    "    - With Stemming we will create a common Vector instead of a seperate Vector for each of the similar words.\n",
    "\n",
    "\n",
    "### Disadvantage of Stemming\n",
    "- We cannot use Stemming for Chatbots because most Stemming classes do not give perfect word_roots for all the words.\n",
    "- Better technique for Chatbots is Lemmitization.\n",
    "\n",
    "### Comparison of PorterStemmer vs RegexpStemmer vs Snowball Stemmer\n",
    "<table border=\"1\" cellpadding=\"8\" cellspacing=\"0\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Aspect</th>\n",
    "      <th>Porter Stemmer</th>\n",
    "      <th>Regexp Stemmer</th>\n",
    "      <th>Snowball Stemmer</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Type</td>\n",
    "      <td>Rule-based algorithmic stemmer</td>\n",
    "      <td>Pattern-based stemmer</td>\n",
    "      <td>Improved rule-based stemmer (Porter v2)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Underlying Approach</td>\n",
    "      <td>Applies a fixed sequence of linguistic rules and suffix stripping</td>\n",
    "      <td>Uses user-defined regular expressions</td>\n",
    "      <td>Applies optimized and standardized stemming rules</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Language Support</td>\n",
    "      <td>English only</td>\n",
    "      <td>Language-agnostic (regex dependent)</td>\n",
    "      <td>Multiple languages</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Configurability</td>\n",
    "      <td>Not configurable</td>\n",
    "      <td>Highly configurable</td>\n",
    "      <td>Limited (predefined per language)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Accuracy</td>\n",
    "      <td>Moderate</td>\n",
    "      <td>Low to Moderate</td>\n",
    "      <td>High</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Consistency</td>\n",
    "      <td>Reasonably consistent</td>\n",
    "      <td>Depends on regex quality</td>\n",
    "      <td>Very consistent</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Handling Edge Cases</td>\n",
    "      <td>Average</td>\n",
    "      <td>Weak</td>\n",
    "      <td>Strong</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Risk of Over-Stemming</td>\n",
    "      <td>Medium</td>\n",
    "      <td>High</td>\n",
    "      <td>Low</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Risk of Under-Stemming</td>\n",
    "      <td>Medium</td>\n",
    "      <td>Medium</td>\n",
    "      <td>Low</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Output Quality</td>\n",
    "      <td>May produce non-words</td>\n",
    "      <td>Often produces non-words</td>\n",
    "      <td>Cleaner stems</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Performance / Speed</td>\n",
    "      <td>Fast</td>\n",
    "      <td>Very fast</td>\n",
    "      <td>Fast</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Ease of Use</td>\n",
    "      <td>Easy</td>\n",
    "      <td>Requires regex expertise</td>\n",
    "      <td>Easy</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Best Use Case</td>\n",
    "      <td>General-purpose English text preprocessing</td>\n",
    "      <td>Custom domain-specific normalization</td>\n",
    "      <td>Production-grade and multilingual NLP pipelines</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Example (studies)</td>\n",
    "      <td>studi</td>\n",
    "      <td>studi / study (depends on regex)</td>\n",
    "      <td>studi</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "      <td>Case</td>\n",
    "      <td>Changes case to Lowercase</td>\n",
    "      <td>Does not change Case</td>\n",
    "      <td>Changes case to Lowercase</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "### Comparsion of Stemming and Lemmatization\n",
    "<table>\n",
    "<tr>\n",
    "    <td></td>\n",
    "    <td>Stemming</td>\n",
    "    <td>Lemmatization</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Definition</td>\n",
    "    <td>A text normalization technique that reduces words to their root form by removing prefixes or suffixes</td>\n",
    "    <td>A text normalization technique that reduces words to their dictionary (base) form, called a <b>lemma</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Linguistic Knowldege</td>\n",
    "    <td>Does not use linguistic rules or vocabulary</td>\n",
    "    <td>Use linguistic rules, morphlogy and vocabulary</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Output (words)</td>\n",
    "    <td>May produce non-meaningful or invalid words</td>\n",
    "    <td>Always produces valid dictionary words</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Accracy</td>\n",
    "    <td>Lower accuracy</td>\n",
    "    <td>Higher accuracy</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Context Awareness</td>\n",
    "    <td>Context free</td>\n",
    "    <td>Context aware (often uses POS tagging)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Part of Speech (POS)</td>\n",
    "    <td>POS not required</td>\n",
    "    <td>POS tagging often required</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Speed / Performance</td>\n",
    "    <td>Faster</td>\n",
    "    <td>Slower due to linguistic analysis</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Example</td>\n",
    "    <td>running -> run, studies -> studi</td>\n",
    "    <td>running -> run, studies -> study</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Handling irregular words</td>\n",
    "    <td>Poor</td>\n",
    "    <td>Excellent</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Language dependency</td>\n",
    "    <td>Mostly language agnostic</td>\n",
    "    <td>Language dependent</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Usecases</td>\n",
    "    <td>Search engines, indexing, quick text processing</td>\n",
    "    <td>Chatbots, semantic analysis, NLP pipelines requiring precision, Q&A, Text summarization</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Common Libraries</td>\n",
    "    <td>NLTK - PortStemmer, SnowballStemmer</td>\n",
    "    <td>NLTK - WordNetLemmatizer, Spacey</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Case</td>\n",
    "    <td>After Stemming, PortStemmer & SnowballStemmer changes the Case of the Stemmed words to Lowercase (Preferred)</td>\n",
    "    <td>After Lemmitization,WordNetLemmatizer does not change the Case of the Lemmitized words to Lowercase</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Preferred Approach</td>\n",
    "    <td>Stemming is not the preferred approach as compared to Lemmitization</td>\n",
    "    <td>Lemmitization is the preferred approach mainly because it has (1) Higher Accuracy than Stemming (2) Uses Context with Language (e.g. English)</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19a36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import RegexpStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c21a3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word = eating, word_root = eat\n",
      "word = eats, word_root = eat\n",
      "word = eaten, word_root = eaten\n",
      "word = writing, word_root = write\n",
      "word = writes, word_root = write\n",
      "word = programming, word_root = program\n",
      "word = programs, word_root = program\n",
      "word = congratulations, word_root = congratul\n"
     ]
    }
   ],
   "source": [
    "#1) Stemming using PorterStemmer\n",
    "# For some words PorterStemmer does not give a valid word_root, e.g. word = congratulations, word_root = congratul\n",
    "corpus=['eating','eats','eaten','writing','writes','programming','programs','congratulations']\n",
    "\n",
    "porter_stemmer=PorterStemmer()\n",
    "for word in corpus:\n",
    "    word_root = porter_stemmer.stem(word)\n",
    "    print(f\"word = {word}, word_root = {word_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eedc400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word = eating, word_root=eat eating eat\n",
      "word = ingeating, word_root=ingeat ingeating ingeat\n"
     ]
    }
   ],
   "source": [
    "#2) Stemming using RegexpStemmer\n",
    "# $ = wild card character, \n",
    "# - ing$ = words ending with 'ing' will be stemmed\n",
    "corpus=['eating','eats','eaten','writing','writes','programming','programs','congratulations']\n",
    "regexp_stemmer = RegexpStemmer('ing$|s$|able$',min=4)\n",
    "\n",
    "word = \"eating\"\n",
    "word_root = regexp_stemmer.stem(word)\n",
    "print (f\"word = {word}, word_root={word_root}\",word,word_root)\n",
    "\n",
    "word = \"ingeating\"\n",
    "word_root = regexp_stemmer.stem(word)\n",
    "print (f\"word = {word}, word_root={word_root}\",word,word_root)\n",
    "# regexp_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad1e349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word = eating, word_root = eat\n",
      "word = eats, word_root = eat\n",
      "word = eaten, word_root = eaten\n",
      "word = writing, word_root = write\n",
      "word = writes, word_root = write\n",
      "word = programming, word_root = program\n",
      "word = programs, word_root = program\n",
      "word = congratulations, word_root = congratul\n"
     ]
    }
   ],
   "source": [
    "#3) Stemming using SnowballStemmer\n",
    "corpus=['eating','eats','eaten','writing','writes','programming','programs','congratulations']\n",
    "\n",
    "snowball_stemmer=SnowballStemmer(\"english\")\n",
    "for word in corpus:\n",
    "    word_root = snowball_stemmer.stem(word)\n",
    "    print(f\"word = {word}, word_root = {word_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db050e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1b6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff20f30f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
